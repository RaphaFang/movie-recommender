{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e06bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把流程濃縮一下（最常見的 join key 清理順序）\n",
    "\n",
    "# 檢查欄位是否存在（有沒有缺失、是不是該有的 key）\n",
    "# 檢查唯一性（該唯一的要唯一，不唯一的要理解為什麼）\n",
    "# 檢查 dtype 一致性（全部轉 str 或 int，避免 join 出錯）\n",
    "# 檢查 join 對應比例（有多少能對上？有多少對不上？）\n",
    "# 正式 join，並檢查 join 後的筆數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8a556a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "ratings = pd.read_csv(\"row_data/MovieLens 20M Dataset/rating.csv\", usecols=[\"userId\", \"movieId\", \"rating\", \"timestamp\"])\n",
    "movies  = pd.read_csv(\"row_data/MovieLens 20M Dataset/movie.csv\", usecols=[\"movieId\", \"title\", \"genres\"])\n",
    "links   = pd.read_csv(\"row_data/MovieLens 20M Dataset/link.csv\", usecols=[\"movieId\", \"imdbId\", \"tmdbId\"])\n",
    "\n",
    "metadata = pd.read_csv(\n",
    "    \"row_data/The Movies Dataset/movies_metadata.csv\",\n",
    "    low_memory=False,\n",
    "    usecols=[\"id\", \"title\", \"genres\", \"overview\", \"release_date\", \"runtime\", \"original_language\"]\n",
    ")\n",
    "credits  = pd.read_csv(\"row_data/The Movies Dataset/credits.csv\")   # columns: id, title, cast, crew\n",
    "keywords = pd.read_csv(\"row_data/The Movies Dataset/keywords.csv\")  # columns: id, keywords\n",
    "\n",
    "# low_memory=False 的作用\n",
    "# 意思是：不要為了省記憶體而分塊推斷 dtype。\n",
    "# 改成 一次讀完整個檔案，再統一推斷 dtype。\n",
    "# 好處：避免 dtype 判斷錯誤、避免很多 DtypeWarning。\n",
    "# 壞處：可能會用比較多記憶體（因為要一次讀完整檔案來判斷）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bd6c0ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45466 entries, 0 to 45465\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   genres             45466 non-null  object \n",
      " 1   id                 45466 non-null  object \n",
      " 2   original_language  45455 non-null  object \n",
      " 3   overview           44512 non-null  object \n",
      " 4   release_date       45379 non-null  object \n",
      " 5   runtime            45203 non-null  float64\n",
      " 6   title              45460 non-null  object \n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# 1.1. 檢查空值\n",
    "metadata[\"id\"].isna().sum() # 檢查出來是0\n",
    "\n",
    "metadata.info() # 但也能這樣直接檢查，看看你要找的欄位跟其他欄位，有沒有Count數字差異"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6666c6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 59 entries, 676 to 16167\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   genres             59 non-null     object \n",
      " 1   id                 59 non-null     object \n",
      " 2   original_language  59 non-null     object \n",
      " 3   overview           59 non-null     object \n",
      " 4   release_date       59 non-null     object \n",
      " 5   runtime            59 non-null     float64\n",
      " 6   title              59 non-null     object \n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 3.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# 1.2.1 檢查重複\n",
    "metadata['id'].duplicated(keep=False)  # 單純這樣會是一個 mask\n",
    "metadata['id'].duplicated(keep=False).sum()  # 59 筆重複\n",
    "\n",
    "dup_ids = metadata[metadata[\"id\"].duplicated(keep=False)].sort_values(\"id\")\n",
    "dup_ids.info()\n",
    "# keep=False 這是多個重複都會顯示\n",
    "# keep=\"first\"（預設）：除了第一次出現以外，其餘重複值標記為 True\n",
    "# keep=\"last\"：除了最後一次出現以外，其餘重複值標記為 True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a0063c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45436"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.2.2 丟掉重複\n",
    "unique_ids_df = metadata.drop_duplicates(subset=[\"id\"], keep=\"first\")\n",
    "\n",
    "len(metadata) # 45466\n",
    "len(unique_ids_df)  # 45436\n",
    "\n",
    "# unique_ids_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "03f7821c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19730    1997-08-20\n",
       "29503    2012-09-29\n",
       "35587    2014-01-01\n",
       "Name: id, dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.3.1 檢查data type，找出奇怪資料 --開始洗資料建立表單\n",
    "\n",
    "mask = ~unique_ids_df['id'].astype(str).str.isdigit()\n",
    "rr = unique_ids_df[mask][\"id\"]\n",
    "\n",
    "# 下面的更推薦，預計是什麼，其他全部不是的都 coerce\n",
    "id_numeric = pd.to_numeric(unique_ids_df[\"id\"], errors=\"coerce\").isna()\n",
    "bad_ids = unique_ids_df.loc[id_numeric, \"id\"]\n",
    "\n",
    "bad_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fb3ea693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           862\n",
       "1          8844\n",
       "2         15602\n",
       "3         31357\n",
       "4         11862\n",
       "          ...  \n",
       "45461    439050\n",
       "45462    111109\n",
       "45463     67758\n",
       "45464    227506\n",
       "45465    461257\n",
       "Name: id, Length: 45433, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.3.2 丟掉怪資料，並且轉換data type\n",
    "\n",
    "subset = unique_ids_df[~unique_ids_df[\"id\"].isin(bad_ids)].copy()\n",
    "subset[\"id\"] = subset[\"id\"].astype(int)\n",
    "\n",
    "subset['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "91333966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9866192536109686)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.4 join 前檢查兩者資料\n",
    "# trans datatype\n",
    "# links[\"tmdbId\"] = links[\"tmdbId\"].astype('Int64')  ## 很奇怪，這會失敗\n",
    "\n",
    "links[\"tmdbId\"] = pd.to_numeric(links[\"tmdbId\"], errors=\"coerce\").astype('Int64')\n",
    "subset[\"id\"] = subset[\"id\"].astype('Int64')\n",
    "\n",
    "# 檢查哪些 tmdbId 存在於 metadata\n",
    "mask = links[\"tmdbId\"].isin(subset[\"id\"])\n",
    "mask.mean()  # True=1, False=0, the mean of this will be the actual ratio\n",
    "# np.float64(0.9866192536109686)\n",
    "\n",
    "# even detail\n",
    "# mask.sum()  # check the amount of matching data\n",
    "# len(mask)   # overall data amount\n",
    "\n",
    "# links[\"tmdbId\"].size ## 27278"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f0580e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pyarrow as pa\n",
    "    for name in [\"pandas.period\", \"pandas.interval\"]:\n",
    "        try:\n",
    "            pa.unregister_extension_type(name)\n",
    "        except Exception:\n",
    "            pass\n",
    "except ImportError:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "deec0217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27278 entries, 0 to 27277\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   movieId            27278 non-null  object\n",
      " 1   title_ml           27278 non-null  object\n",
      " 2   genres_ml          27278 non-null  object\n",
      " 3   tmdbId             27026 non-null  object\n",
      " 4   genres_tmdb        26913 non-null  object\n",
      " 5   id                 26913 non-null  object\n",
      " 6   original_language  26910 non-null  object\n",
      " 7   overview           26641 non-null  object\n",
      " 8   release_date       26886 non-null  object\n",
      " 9   runtime            26855 non-null  object\n",
      " 10  title_tmdb         26912 non-null  object\n",
      "dtypes: object(11)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# 5. join，並檢查 join 後的筆數\n",
    "# 5.1. 確保 dtype 一致\n",
    "movies[\"movieId\"] = movies[\"movieId\"].astype(\"Int64\")\n",
    "links[\"movieId\"] = links[\"movieId\"].astype(\"Int64\")\n",
    "links[\"tmdbId\"] = pd.to_numeric(links[\"tmdbId\"], errors=\"coerce\").astype('Int64')\n",
    "subset[\"id\"] = subset[\"id\"].astype('Int64')\n",
    "\n",
    "# 5.2. movies + links\n",
    "movies_links = movies.merge(links[[\"movieId\", \"tmdbId\"]], on=\"movieId\", how=\"left\")\n",
    "movies_links\n",
    "\n",
    "# 5.3. 再跟 metadata join\n",
    "movies_full = movies_links.merge(\n",
    "    subset[['genres', 'id', 'original_language', 'overview', 'release_date',\n",
    "       'runtime', 'title']],\n",
    "    left_on=\"tmdbId\",\n",
    "    right_on=\"id\", # we get different col names here, the reason to clearly define left/right\n",
    "    how=\"left\",    # left join: 保留 MovieLens 所有電影，即使 metadata 沒對上\n",
    "    suffixes=(\"_ml\", \"_tmdb\")\n",
    ")\n",
    "\n",
    "movies_full['movieId'] = movies_full['movieId'].astype(object)\n",
    "movies_full['tmdbId'] = movies_full['tmdbId'].astype(object)\n",
    "movies_full['id'] = movies_full['id'].astype(object)\n",
    "movies_full['runtime'] = movies_full['runtime'].astype(object)\n",
    "\n",
    "movies_full.info()\n",
    "movies_full.to_parquet(\"movie_link_metadata.parquet\",engine=\"fastparquet\")\n",
    "\n",
    "# print(\"原始 MovieLens 電影數：\", movies.shape[0])\n",
    "# print(\"join 後電影數：\", movies_full.shape[0])\n",
    "# print(movies_full.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9350f938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask.mean()  # True=1, False=0, the mean of this will be the actual ratio\n",
    "# np.float64(0.9866192536109686)\n",
    "\n",
    "# links[\"tmdbId\"].size ## 27278\n",
    "\n",
    "# 很奇怪，前面明明沒有完全批配，但是 merge() 的是具又是完全批配的？\n",
    "\n",
    "# 27278 rows × 11 columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a698537b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
